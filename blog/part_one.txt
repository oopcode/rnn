<sub><sup>[Часть №2: сеть Элмана](http://chisquared.org/post/recurrent-neural-networks-part-2-elman-rnn)</sup></sub>

[Рекуррентные нейронные сети](https://ru.wikipedia.org/wiki/Рекуррентная_нейронная_сеть) (далее RNNs, от англ. *Recurrent Neural Network*) – интересный тип нейронных сетей, которые предназначены для работы с последовательностями данных.

Обычные нейронные сети прямого распространения сети не имеют "памяти". То есть, если мы предъявляем такой сети какой-нибудь пример, её предсказание всегда будет одинаковым вне зависимости от того, какие примеры мы предъявляли ей ранее. При решении некоторых задач требуется другой подход; например, если мы пытаемся предсказать следующее слово в каком-нибудь тексте, нас естественным образом интересуют чуть ли не все слова, которые встречались нам ранее.

Рекуррентные нейронные сети решают именно этот класс задач. Существует несколько наиболее известных типов RNN: это простые сети [Джордана](https://ru.wikipedia.org/wiki/Нейронная_сеть_Джордана) и [Элмана](https://ru.wikipedia.org/wiki/Нейронная_сеть_Элмана), а также более сложные и [до смешного эффективные](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) сети (от англ. *Long Short-Term Memory*).

Все эти сети будут рассмотрены в следующих статьях данного цикла. Здесь же мы попытаемся вспомнить, что представляет из себя обычная сеть прямого распространения (далее FFN, от англ. *feedforward*).

Главная причина, по которой нам может быть полезно вспомнить устройство этих сетей – это два алгоритма, использующиеся для обучения FFN: *алгоритм обратного распространения ошибки* (англ. *backpropagation*) и *алгоритм стохастического градиентного спуска* (англ. *Stochastic gradient descent*). Дело в том, что для обучения простых RNN используется слегка модифицированная версия этого алгоритма, называющаяся *Backpropagation through time, BPTT*.

Данная статья основана на [вот этом](http://neuralnetworksanddeeplearning.com/chap2.html) материале. В случае затруднений рекомендую ознакомиться с первоисточником.

Код для статьи написан на языке Go и лежит в [репозитории](https://github.com/oopcode/rnn/tree/master/basicNN) на Github'е. Я старался писать код настолько просто и понятно, насколько это вообще возможно, однако стоит заметить, что без хотя бы общего знакомства с основами [линейной алгебры](https://www.khanacademy.org/math/linear-algebra) изучать нейронные сети не имеет смысла.

Для каждого математического выражения в статье мы будем приводить реализующий его участок кода. В каком-то смысле ценность данного материала заключается именно в его плотной связи с программной реализацией; эта связь поможет читателю "прочувствовать" все описываемые алгоритмы.

Итак, простейшая сеть прямого распространения с одним скрытым слоем выглядит приблизительно следующим образом:

<img width="30%" height="50%" src="/static/pics/feedforward_nn.png">

Как можно видеть, во входном слое 3 нейрона, в скрытом слое 4 нейрона, а во внешнем слое 2 нейрона. Нейроны прилегающих слоев соединены весами по принципу "каждый с каждым"; их можно изобразить в виде матрицы. В нашем случае матрица весов между входным и скрытым слоем может выглядеть вот так:

$$ \begin{bmatrix} w\_{1, 1} & w\_{1, 2} & w\_{1, 3} \\\ w\_{2, 1} & w\_{2, 2} & w\_{2, 3} \\\ w\_{3, 1} & w\_{3, 2} & w\_{3, 3} \\\ w\_{4, 1} & w\_{4, 2} & w\_{4, 3} \end{bmatrix} $$

Здесь $ w\_{3, 2} $ – это вес от 2-го нейрона входного слоя к 3-му нейрону скрытого слоя. Размерность этой матрицы – $ 4 \times 3 $, по числу нейронов в скрытом и входном слое соответственно. Очевидно, что размерность матрицы весов между нейронами скрытого и внешнего слоя в нашем примере будет $ 2 \times 4 $.

Также мы должны иметь какое-то представление для [порогов](http://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks) (сдвигов, англ. *bias*) каждого нейрона. Сдвиги нейронов скрытого слоя можно представить в виде вектора:

$$ \begin{bmatrix} b\_{1} & b\_{2} & b\_{3} & b\_{4}  \end{bmatrix}, $$

где $ b\_{2} $ – это сдвиг 2-го нейрона скрытого слоя. Заметим, что пороги входного слоя нам не нужны (потому что информация на них подается напрямую, без использования весов).

В начале обучения веса и пороги необходимо инициализировать маленькими случайными весами. Мы выберем случайные значения в промежутке $ [-1, 1] $; это не лучшая стратегия инициализации, однако для наших целей хватит и этого.

Посмотрим на то, как выглядит в коде наша нейронная сеть. Заметим, что для простоты мы жестко задали набор слоев (входной, один скрытый и внешний); это позволит нам избежать лишней индексации и сильно повысит читаемость кода.

```
type NN struct {
	η  float64   // Learning rate
	IH *m.Dense  // Weights from input layer to hidden layer
	HO *m.Dense  // Weights from hidden layer to output layer
	HB *m.Vector // Biases for hidden neurons
	OB *m.Vector // Biases for output neurons
}

// NewNN is a constructor for the NN type.
func NewNN(args *Args) *NN {
	out := &NN{
		η: args.Eta,
	}
	out.IH = m.NewDense(args.NumHid, args.NumInp, nil)
	out.HO = m.NewDense(args.NumOut, args.NumHid, nil)
	out.HB = m.NewVector(args.NumHid, nil)
	out.OB = m.NewVector(args.NumOut, nil)
	// Initialize weights at random
	c.RandomDense(-1., 1., out.IH)
	c.RandomDense(-1., 1., out.HO)
	// Same for hidden and output biases
	c.RandomVector(-1., 1., out.HB)
	c.RandomVector(-1., 1., out.OB)
	return out
}

```

<sub><sup>В коде выше $ η $ – константа, которая задает шаг обучения, она понадобится нам на этапе реализации алгоритма стохастического градиентного спуска.</sup></sub>

Итак, мы решили хранить веса в матричной форме. Возникает вопрос: почему именно матрицы? Ответ: потому что все необходимые операции над весами в нейронной сети прекрасно описываются простейшими операциями над матрицами и векторами. Наиболее наглядно это можно продемонстрировать на примере распространения активации нейронов от входного слоя к внешнему (англ. *forward pass*).

Как мы помним, активация (выход) нейрона описывается следующим образом:

$$ \begin{eqnarray} a^{l}\_j = \sigma\left( \sum_k w^{l}\_{j,k} a^{l-1}\_k + b^l\_j \right) \tag{1}\end{eqnarray} $$

Разберем это выражение по порядку:

1. $ w^{l}\_{j,k} $: вес от $k-$го нейрона в слое $ (l - 1) $ к $j-$му нейрону в слое $ l $;
2. $ a^{l-1}\_k $: выход $k-$го нейрона в слое $ (l - 1) $;
3. $ b^l\_j  $: порог $j-$го нейрона в слое $ l $;
4. $ \sigma(\cdot) $: функция активации, чаще всего [логистическая функция](https://en.wikipedia.org/wiki/Logistic_function) или [гиперболический тангенс](https://en.wikipedia.org/wiki/Hyperbolic_function).

<sub><sup>Обе функции в п. 4 принадлежат семейству функций класса *сигмоид*, и это не случайность: их производные очень легко вычислить, и уже очень скоро мы воспользуемся этим.</sup></sub>

Таким образом, выходом нейрона является результат применения функции активации ко взвешенной сумме выходов всех нейронов с предыдущего слоя. Теперь попытаемся понять, почему представление весов в виде матрицы (а порогов в виде векторов) удобно для подобных вычислений.

Вспомним, что такое произведение матрицы на вектор. Допустим, у нас есть матрица $ W^l $ весов между слоями $ l $ и $ (l - 1) $, а также активации $ a $ нейронов слоя $ (l - 1) $. Договоримся обозначать взвешенную сумму на входе $j-$го нейрона в слое $ (l) $ через 

$$ \begin{eqnarray} z_j^l = \sum_k w^{l}\_{j,k} a^{l-1}\_k. \tag{2} \end{eqnarray} $$ 

Тогда произведение $ W^la $ будет равно:

$$ \begin{bmatrix} w^{l}\_{1, 1} & w^{l}\_{1, 2} & w^{l}\_{1, 3} \\\ w^{l}\_{2, 1} & w^{l}\_{2, 2} & w^{l}\_{2, 3} \\\ w^{l}\_{3, 1} & w^{l}\_{3, 2} & w^{l}\_{3, 3} \\\ w^{l}\_{4, 1} & w^{l}\_{4, 2} & w^{l}\_{4, 3} \end{bmatrix} \times \begin{bmatrix} a^{l-1}\_1 \\\ a^{l-1}\_2 \\\ a^{l-1}\_3 \end{bmatrix} = \begin{bmatrix} a^{l-1}\_1w^{l}\_{1, 1} + a^{l-1}\_2w^{l}\_{1, 2} + a^{l-1}\_3w^{l}\_{1, 3} \\\ a^{l-1}\_1w^{l}\_{2, 1} + a^{l-1}\_2w^{l}\_{2, 2} + a^{l-1}\_3w^{l}\_{2, 3} \\\ a^{l-1}\_1w^{l}\_{3, 1} + a^{l-1}\_2w^{l}\_{3, 2} + a^{l-1}\_3w^{l}\_{3, 3} \\\ a^{l-1}\_1w^{l}\_{4, 1} + a^{l-1}\_2w^{l}\_{4, 2} + a^{l-1}\_3w^{l}\_{4, 3} \end{bmatrix} = \begin{bmatrix} \sum\_{k=1}^{3} w^{l}\_{1,k} a^{l-1}\_k \\\ \sum\_{k=1}^{3} w^{l}\_{2,k} a^{l-1}\_k \\\ \sum\_{k=1}^{3} w^{l}\_{3,k} a^{l-1}\_k \\\ \sum\_{k=1}^{3} w^{l}\_{4,k} a^{l-1}\_k  \end{bmatrix} $$

Иными словами, мы сразу же получаем взвешенные суммы на входе всех нейронов в слое $ (l) $.  Теперь чтобы найти активации всех нейронов в слое $ (l) $ достаточно просто прибавить к полученному вектору вектор порогов для $ (l) $ и применить функцию активации. Итак, мы можем переписать $ (1) $ в векторной форме:

$$ \begin{eqnarray} a^{l} = \sigma(w^l a^{l-1}+b^l) \tag{3}\end{eqnarray} $$

Когда мы получили активации нейронов скрытого слоя (в нашем случае он один), мы можем точно так же использовать их для получения активаций внешнего слоя (то есть, получить "предсказание" сети). Посмотрим, как реализуется процедура передачи активации со входного слоя на внешний в коде:

```
func (n *NN) Forward(input *m.Vector) (sums *Sums, acts *Acts) {
	// Same as getting the weighted sum of inputs for all hidden neurons
	// plus the hidden bias
	hidSums := c.GetAddVec(
		c.GetMulVec(n.IH, input),
		n.HB,
	)
	// Apply sigmoid function to each hidden neuron (getting the activation)
	hidActs := c.GetVectorSigmoid(hidSums)
	// Same as getting the weighted sum of inputs for all output neurons
	// plus the output bias
	outSums := c.GetAddVec(
		c.GetMulVec(n.HO, hidActs),
		n.OB,
	)
	// Apply sigmoid function to each output neuron (getting the activation)
	outActs := c.GetVectorSigmoid(outSums)
	sums = &Sums{
		Out: outSums,
		Hid: hidSums,
	}
	acts = &Acts{
		Out: outActs,
		Hid: hidActs,
		Inp: input,
	}
	return
}
```
<sub><sup>Можно заметить, что мы возвращаем все "промежуточные" результаты работы алгоритма: взвешенные суммы и активации для скрытого и внешнего слоёв. Эти значения будут нам нужны далее для реализации алгоритма обратного распространения ошибки.</sup></sub>

Поговорим теперь о процедуре обучения.  Наша обучающая выборка состоит из набора пар векторов, в каждой из которых первый вектор – это собственно обучающий пример (в нем закодирована информация о каком-нибудь объекте внешнего мира), а второй – его *класс*, который представлен one-hot вектором. Такая пара может выглядеть следующим образом:

$$ \left( \begin{bmatrix} 0.63 \\\ 0.11 \\\ 0.52 \\\ 0.97 \end{bmatrix},  \begin{bmatrix} 1 \\\ 0 \\\ 0 \end{bmatrix} \right) $$

Объект, описываемый первым вектором в этой паре, принадлежит первому из трех возможных классов.

В первом приближении обучение сети выглядит так:

1. На вход сети подается обучающий пример-вектор;
2. Активация распространяется до внешнего слоя;
3. Выход сети сравнивается с желаемым, вычисляется *ошибка сети*;
4. На основе этой ошибки сеть пытается изменить свои параметры в лучшую сторону.

В данном материале мы будем пользоваться среднеквадратичной ошибкой:

$$ \begin{eqnarray} C = \frac{1}{2} \|y-a^L\|^2 = \frac{1}{2} \sum_j (y_j-a^L_j)^2, \tag{4}\end{eqnarray} $$ 

где $ y $ – это ожидаемая активация примера (тот самый one-hot вектор). Несложно проверить то, что чем больше разница между выходом сети и ожидаемой активацией, тем больше значение, возвращаемое выражением в $ (4) $.

Все это интуитивно понятно и просто. Однако главный вопрос заключается в том, как именно сеть будет пытаться "изменить свои параметры в лучшую сторону", узнав об ошибке.

Определимся вначале с тем, что именно будет меняться. Очевидно, что предсказание сети для конкретного примера полностью определяется тем, какие в этой сети веса и пороги. Соответственно, ошибку сети для фиксированного примера можно рассматривать как *функцию* $ Err(W\kern -0.3ex, B) $ от всех весов и порогов этой сети. Аргументов у этой функции ровно *(количество весов)* $ + $ *(количество порогов)*, мы записываем это как $ W\kern -0.3ex, B $ просто для удобства.

Поскольку мы всегда хотим минимизировать ошибку, мы должны узнать для каждого веса и порога, как его нужно изменить, чтобы значение $ Err(W\kern -0.3ex, B) $ уменьшилось.

К счастью, в функциональном анализе уже давно придумали способ узнать, как зависит значение функции от изменения одного из аргументов, и это [частная производная](https://ru.wikipedia.org/wiki/Частная_производная).

<sub><sup>Понимание дальнейшего материала фактически невозможно без умения вычислять частные производные и знания [цепного правила](https://ru.wikipedia.org/wiki/Дифференцирование_сложной_функции). При необходимости рекомендуется потратить какое-то время на освоение этих понятий.</sup></sub>

То есть, всё что нам нужно – это вычислить $ \partial Err / \partial w^l_{j,k} $ и $ \partial Err / \partial b^l_j $ для каждого из весов и порогов сети.

Если $ \partial Err / \partial w^l\_{j,k} $ принимает большое *положительное* значение, это значит, что с увеличением $ w^l\_{j,k} $ ошибка быстро *растет*; если же $ \partial Err / \partial w^l\_{j,k} $ принимает большое *отрицательное* значение, это значит, что с увеличением $ w^l\_{j,k} $ ошибка быстро *убывает*. Это значит, что если вычесть из текущего значения веса частную производную ошибки по этому весу, то величина ошибки в любом случае уменьшится (то же самое верно для значений порогов):

$$ \begin{eqnarray} w^l\_{j,k} - \eta \frac{\partial Err } {\partial w^l\_{j,k}} \tag{5}\end{eqnarray} $$ 

Здесь $ \eta $ – это *коэффициент скорости обучения* (англ. *learning rate*), дополнительная константа, которая регулирует то, насколько "решительно" мы меняем значение весов при обучении. В коде это будет выглядеть вот так:

```
func (n *NN) Update(input, expected *m.Vector) {
	dErrdIH, dErrdHO, dErrdHB, dErrdOB := n.BackProp(input, expected)
	ηIH := c.GetDenseApply(dErrdIH, func(val float64) float64 {
		return val * n.η
	})
	ηHO := c.GetDenseApply(dErrdHO, func(val float64) float64 {
		return val * n.η
	})
	ηHB := c.GetVectorApply(dErrdHB, func(val float64) float64 {
		return val * n.η
	})
	ηOB := c.GetVectorApply(dErrdOB, func(val float64) float64 {
		return val * n.η
	})
	n.IH.Sub(n.IH, ηIH)
	n.HO.Sub(n.HO, ηHO)
	n.HB.SubVec(n.HB, ηHB)
	n.OB.SubVec(n.OB, ηOB)
}
```
<sub><sup>*n.BackProp(input, expected)* – это процедура обратного распространения, возвращающая частные производные ошибки по весам и порогам скрытого и внешнего слоя. Мы опишем принцип её работы ниже. *c.GetDenseApply()* применяет переданную вторым аргументом функцию к каждому элементу первого аргумента (матрицы) и возвращает результат (также матрицу).</sup></sub>

Собственно, теперь нужно понять, как именно найти $ \partial Err / \partial w^l_{j,k} $ и $ \partial Err / \partial b^l_j $, используя имеющиеся у нас данные.

Вычислять $ \partial Err / \partial w^{l}\_{j,k} $ мы будем последовательно, начиная с нейронов внешнего слоя сети, потому что их активацию можно напрямую сравнивать с желаемым результатом. Активацию каждого нейрона можно представить как $ a^{l}\_{j} = \sigma(z^{l}\_{j}(\cdot)) $, где $ z^{l}\_{j}(\cdot) $ -- это промежуточная функция, берущаяся "напрямую" от взвешенной суммы весов, входящих в нейрон, и его порога:

$$ \begin{eqnarray} z^{l}\_{j} = w^l a^{l-1}+b^l. \tag{6}\end{eqnarray} $$

 Мы пишем "напрямую", потому что её производные по всем аргументам вычисляются достаточно элементарно (лучше прочувствовать логику за этим утверждением можно [здесь](http://colah.github.io/posts/2015-08-Backprop/)). Эта промежуточная функция нам нужна для того, чтобы применить цепное правило дифференцирования для нахождения $ \partial Err / \partial w^{l}\_{j,k} $.

Мы будем расценивать $ \delta^{l}\_{j} \partial Err / \partial z^{l}\_{j} $ в качестве *ошибки* $ j- $го нейрона в слое $ l $. В каком-то смысле это просто условность, позволяющая дать $ \delta^{l}\_{j} $ свое собственное значащее имя; однако у такого выбора есть некая мотивация. Большое абсолютное значение $ \delta^{l}\_{j} $ говорит о том, что даже маленькое изменение $ z^{l}\_{j}(\cdot) $ оказывает серьезное влияние на общую ошибку сети, и тогда нейрон $ a^{l}\_{j} $ можно считать "недообученным" (большая ошибка); с другой стороны, если $ \delta^{l}\_{j} $ близко к нулю, то изменение поведения нейрона в целом мало влияют на поведение сети, и его можно "оставить в покое" (маленькая ошибка). Хотя, конечно, с такой интерпретацией можно поспорить; как уже было сказано выше, выделение $ z^{l}\_{j}(\cdot) $ в отдельную функцию нужно исключительно для удобства вычислений.

<sup><sup>Нужно понимать, что мы с таким же успехом могли бы использовать в качестве "ошибки" производную по самой активации нейрона $ \partial Err / \partial a^{l}\_{j} $, поскольку её влияние на общую ошибку сети индентично влиянию $ \delta^{l}\_{j} $. Мы не делаем этого, опять же, только из-за удобства вычислений.</sup></sup>

Рассмотрим далее, как мы можем использовать $ \delta^{l}\_{j} $ для вычисления $ \partial Err / \partial w^{l}\_{j,k} $. Мы будем сначала давать готовое выражение для вычисления каждой промежуточной величины, а затем объяснять, как мы к нему пришли.

Начнем с ошибок нейронов на **внешнем** слое сети ($ L $):

$$ \begin{eqnarray} \delta^{L}\_{j} = \frac{\partial Err}{\partial a^{L}\_{j}} \sigma'(z^{L}\_{j}) = (a^{L} - y)\odot\sigma'(z^{L}). \tag{7}\end{eqnarray} $$

<sup><sup>Здесь $\odot $ – это [поэлементное](https://ru.wikipedia.org/wiki/Произведение_Адамара) умножение векторов, а крайнее правое выражение, разумеется, записано в векторной форме.</sup></sup>

*Доказательство.* Поскольку по нашему определению $ \delta^{L}\_{j} = \partial Err / \partial z^{L}\_{j} $, мы можем применить цепное правило и переписать данное выражение с учетом частных производных по активациям нейронов внешнего слоя (сумма по $ k $):

$$ \delta^L\_j = \sum\_k \frac{\partial Err}{\partial a^L\_k} \frac{\partial a^L\_k}{\partial z^L\_j} $$

Поскольку $ a^L\_j = \sigma(z^L\_j) $, второй множитель в выражении выше может быть переписан как $ \sigma'(z^L\_j) $:

$$ \delta^L\_j = \frac{\partial Err\_{ }}{\partial a^{L}\_{j}} \sigma'(z^L\_j). $$

Последнее упрощение из $ (7) $ возможно вследствие того, что наша функция ошибки выглядит как $ \frac{1}{2} \sum\_j (a\_j-y\_j)^2 $, и соответственно $ \partial Err / \partial a^L\_j = (a\_j-y\_j) $.

В коде нахождение ошибки внешнего слоя выглядит следующим образом:

```
func (n *NN) GetOutError(outActs, outSums, expected *m.Vector) *m.Vector {
    // Output activations minus expected activations
	outError := c.GetSubVec(outActs, expected)
	// Element-wise multiplication by sigma'(weighted sums on output neurons)
	return c.GetMulElemVec(outError, c.GetVectorSigmoidPrime(outSums))
}
```

Теперь, когда мы знаем, как найти ошибку нейронов на внешнем слое, определим **ошибку в слое** $ l $ в зависимости от ошибки слоя $ (l + 1) $:

\begin{eqnarray} \delta^l = ((w^{l+1})^T \delta^{l+1}) \odot \sigma'(z^l). \tag{8}\end{eqnarray}

*Доказательство.* Мы выразим $ \delta^l\_j = \frac{\partial Err\_{ }}{\partial z^l\_j} $ через $ \delta^{l+1}\_j $ при помощи того же цепного правила:

$$\delta^l\_j = \frac{\partial C}{\partial z^l\_j} = \sum\_k \frac{\partial C}{\partial z^{l+1}\_k} \frac{\partial z^{l+1}\_k}{\partial z^l\_j} = \sum\_k \frac{\partial z^{l+1}\_k}{\partial z^l\_j} \delta^{l+1}\_k.$$


Здесь второе преобразование – это просто формулировка цепного правила, а в последнем преобразовании мы заменяем $ \frac{\partial z^{l+1}\_k }{\partial z^l\_j} $ на ошибку слоя $ (l + 1) $, $ \delta^{l+1}\_k. $ Эта ошибка вычисляется нами до слоя $ l $ и используется "как есть"; именно для этого нам была нужна ошибка внешнего слоя $ \delta^{L}\_{j} $ – она дает нам то, с чего можно начать вычислять ошибки всех предшествующих скрытых слоев.

Для того, чтобы упростить $ \frac{\partial z^{l+1}\_k}{\partial z^l\_j} $ в последнем преобразовании, вспомним, что

$$ z^{l+1}\_k = \sum\_j w^{l+1}_{k,j} a^l\_j +b^{l+1}_k = \sum\_j w^{l+1}\_{k,j} \sigma(z^l\_j) +b^{l+1}\_k. $$

Это значит, что производная по $ z^{l}\_k $ будет равна

$$ \frac{\partial z^{l+1}\_k}{\partial z^l\_j} = w^{l+1}\_{k,j} \sigma'(z^l\_j), $$

и тогда 

$$ \delta^l\_j = \sum\_k w^{l+1}\_{k,j}  \delta^{l+1}\_k \sigma'(z^l_j) = ((w^{l+1})^T \delta^{l+1}) \odot \sigma'(z^l), $$ 

что и требовалось доказать. Может возникнуть вопрос: откуда взялась транспозиция матрицы весов? Все очень просто: по большому счету мы просто передаем *ошибки* со слоя $ (l + 1) $ слою $ l $ тем же способом, которым ранее передавали передавали *активации* с $ l $ на $ (l + 1) $. Соответственно, нам требуется обратная размерность матрицы весов. Собственно, именно из-за этого сходства сам алгоритм назван *обратным распространением ошибки*.

Как обычно, приведем пример реализации получения ошибок на любом слое:

```
func (n *NN) GetError(prevErrs, currSums *m.Vector, w *m.Dense) *m.Vector {
	wT := c.GetTransposed(w)
	propagated := c.GetMulVec(wT, prevErrs)
	return c.GetMulElemVec(propagated,
		c.GetVectorSigmoidPrime(currSums))
}
```

Теперь мы подобрались к самому главному: **производной ошибки** непосредственно **по весам и порогам**. Здесь мы дадим искомые равенства без доказательства, оставив его читателю в качестве упражнения.

<details><summary><small>Шучу, вот доказательство.</small></summary>
Пока не успел, но скоро будет.
</details>

$$ \begin{eqnarray} \frac{\partial C}{\partial w^l\_{j,k}} = a^{l-1}\_k \delta^l\_j \tag{9}\end{eqnarray} $$

$$ \begin{eqnarray} \frac{\partial C}{\partial b^l\_j} = \delta^l\_j \tag{10} \end{eqnarray} $$

Полная процедура получения производных ошибки по всем весам и порогам сети в коде выглядит следующим образом:

```
func (n *NN) BackProp(input, expected *m.Vector) (
	dErrdIH, dErrdHO *m.Dense, dErrdHB, dErrdOB *m.Vector) {
	// Get weighted sums and activations for all layers
	sums, acts := n.Forward(input)
	// Calculate error for each neuron in the output layer
	outErrs := n.GetOutError(sums.Out, acts.Out, expected)
	// Calculate error for each neuron in the hidden layer using output layer's
	// errors
	hidErrs := n.GetError(outErrs, sums.Hid, n.HO)
	hoRows, hoCols := n.HO.Dims()
	dErrdHO = m.NewDense(hoRows, hoCols, nil)
	dErrdHO.Outer(1., outErrs, acts.Hid)
	// And then we'll do the same for weights from input to hidden layer:
	ihRows, ihCols := n.IH.Dims()
	dErrdIH = m.NewDense(ihRows, ihCols, nil)
	dErrdIH.Outer(1., hidErrs, acts.Inp)
	// Error gradients on hidden and output layer biases are just the errors
	// on those layers
	dErrdHB, dErrdOB = hidErrs, outErrs
	return
}

```

Этот код требует некоторых комментариев, а точнее лишь та его часть, где мы вычисляем *dErrdHO.Outer(1., outErrs, acts.Hid)*. Мы могли бы вычислить производные для каждого веса от скрытого слоя к внешнему "напрямую", используя вложенные циклы:

```
hoRows, hoCols := n.HO.Dims()
dErrdHO = m.NewDense(hoRows, hoCols, nil)
for j := 0; j < hoRows; j++ {
	for k := 0; k < hoCols; k++ {
		grad := acts.Hid.At(k, 0) * outErrs.At(j, 0)
		dErrdHO.Set(j, k, grad)
	}
}
```

Однако то, что мы здесь делаем, называется [внешним произведением](https://en.wikipedia.org/wiki/Outer_product) векторов и реализовано в большинстве приличных библиотек, так что мы используем более короткую и читаемую версию.

Собственно, теперь у нас есть полное представление о том, как работает простая нейронная сеть прямого распространения. Мы можем проверить эту сеть, используя следующую процедуру:

```
func (n *NN) RunEpochs(numEpochs int, input, expected *m.Dense) {
	numInputs, _ := input.Dims()
	// For each epoch
	for epoch := 0; epoch < numEpochs; epoch++ {
		// For each input
		for i := 0; i < numInputs; i++ {
			currInp := input.RowView(i)
			currExp := expected.RowView(i)
			// update the weights
			n.Update(currInp, currExp)
		}
		// Gather predictions
		predictions := []*m.Vector{}
		for i := 0; i < numInputs; i++ {
			currInp := input.RowView(i)
			_, acts := n.Forward(currInp)
			predictions = append(predictions, acts.Out)
		}
		// Get the total number of correctly classified items
		_, totalOk := c.GetClassAccuracy(predictions, expected)
		if (epoch % 100) == 0 {
			fmt.Printf("Epoch %d; %v out of %v predictions correct\n",
				epoch, totalOk, numInputs)
		}
	}
}
```
<sup><sup>Здесь мы просто несколько раз предъявляем сети весь обучающий набор данных по одному примеру за раз. Этот способ обучения соответствует способу *mini-batch* с размером серии, равным 1. Единственное, чем наш способ обучения хуже *mini-batch* – это скоростью обучения (мы не можем воспользоваться ускорением, которое получается вследствие представления всех обучающих примеров серии в виде одной матрицы). </sup></sup>

На [ирисах Фишера](https://ru.wikipedia.org/wiki/Ирисы_Фишера) процесс обучения сети выглядит вот так:

```
================================================
Testing basic feed-forward NN on Iris dataset:
================================================
Epoch 0; 50 out of 150 predictions correct
Epoch 100; 30 out of 150 predictions correct
Epoch 200; 95 out of 150 predictions correct
Epoch 300; 118 out of 150 predictions correct
Epoch 400; 100 out of 150 predictions correct
Epoch 500; 100 out of 150 predictions correct
Epoch 600; 100 out of 150 predictions correct
Epoch 700; 100 out of 150 predictions correct
Epoch 800; 102 out of 150 predictions correct
Epoch 900; 106 out of 150 predictions correct
Epoch 1000; 110 out of 150 predictions correct
Epoch 1100; 115 out of 150 predictions correct
Epoch 1200; 122 out of 150 predictions correct
Epoch 1300; 127 out of 150 predictions correct
Epoch 1400; 134 out of 150 predictions correct
Epoch 1500; 137 out of 150 predictions correct
Epoch 1600; 139 out of 150 predictions correct
Epoch 1700; 139 out of 150 predictions correct
Epoch 1800; 144 out of 150 predictions correct
Epoch 1900; 144 out of 150 predictions correct
Epoch 2000; 144 out of 150 predictions correct
Epoch 2100; 145 out of 150 predictions correct
Epoch 2200; 145 out of 150 predictions correct
Epoch 2300; 145 out of 150 predictions correct
Epoch 2400; 146 out of 150 predictions correct
Epoch 2500; 147 out of 150 predictions correct
Epoch 2600; 147 out of 150 predictions correct
Epoch 2700; 147 out of 150 predictions correct
Epoch 2800; 147 out of 150 predictions correct
Epoch 2900; 147 out of 150 predictions correct
Epoch 3000; 147 out of 150 predictions correct
```

Указания по запуску кода можно прочитать в описании [репозитория](https://github.com/oopcode/rnn/tree/master/basicNN) на Github'е (на самом деле это одна команда в терминале).

Итак, в данной статье мы разобрались с обучением простой сети прямого распространения. В [следующей](следующая-статья) статье мы точно так же рассмотрим простейшую рекуррентную сеть Элмана и один из способов её реализации в коде.